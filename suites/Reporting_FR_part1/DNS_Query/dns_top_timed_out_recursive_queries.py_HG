"""
 Copyright (c) Infoblox Inc., 2016

 ReportName          : DNS Top Timed-Out Recursive Queries 
 ReportCategory      : DNS Query
 Number of Test cases: 1
 Execution time      : 302.61 seconds
 Execution Group     : Hourly Group (HG)
 Description         : DNS Top Timed-Out Recursive Queries reports will be updated every 1 hour

 Author : Raghavendra MN
 History: 06/04/2016 (Created)
"""
import config
import json
import os
import pytest
import pexpect
import re
import sys
import subprocess
from time import sleep
import unittest

import ib_utils.ib_NIOS as ib_NIOS
import ib_utils.ib_get as ib_get
from logger import logger
from ib_utils.ib_system import search_dump as search_dump
from ib_utils.ib_validaiton import compare_results as compare_results
"""
TEST Steps:
      1.  Input/Preparaiton      : This is Hourly Report and Preparation is injected separately.
      2.  Search                 : Search with Default Filter
      3.  Validation             : Validating Search result against input data
				   Due to of other report preparation, % value in Domain Name (say "Domain Name":"hello.com.(25.0%)") is not possible. 
                                   So, % calculation will be done after performing search operation based on total number of queries 
                                   and validating only Number of Queries. 								
"""
class DNSTopRequestedTimedOutRecursiveQueries(unittest.TestCase):
    @classmethod
    def setup_class(cls):
        logger.info('-'*15+"START:DNS Top Timed Out Recursive Queries"+'-'*15)
        logger.info("Performing Query through Query perf")
        cls.test1=[]
        cls.test1=[ \
        {"Domain Name": "domain1.top_timed_out_recursive_queries.com", "Queries": "100" }, \
        {"Domain Name": "domain2.top_timed_out_recursive_queries.com", "Queries": "90"}, \
        {"Domain Name": "domain3.top_timed_out_recursive_queries.com", "Queries": "80"}, \
        {"Domain Name": "1.0.0.56.in-addr.arpa", "Queries": "70"}, \
        {"Domain Name": "2.0.0.56.in-addr.arpa", "Queries": "60"}, \
        {"Domain Name": "3.0.0.56.in-addr.arpa", "Queries": "50"}, \
        {"Domain Name": "1.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.6.6.6.6.ip6.arpa", "Queries": "40"}, \
        {"Domain Name": "2.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.6.6.6.6.ip6.arpa", "Queries": "30"}, \
        {"Domain Name": "3.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.6.6.6.6.ip6.arpa", "Queries": "20"}]
        logger.info ("Json input for validation test1")
        logger.info(json.dumps(cls.test1, sort_keys=True, indent=4, separators=(',', ': ')))
        
    def test_1_dns_top_requested_timed_out_recursive_queries(self):
        logger.info(sys._getframe().f_code.co_name)
        search_str=r"search index=ib_dns_summary report=si_top_timeout_queries | lookup dns_viewkey_displayname_lookup VIEW output display_name | bucket span=1h _time | stats sum(COUNT) as SFT_QUERIES by NAME | sort -SFT_QUERIES | head 20 | eventstats  sum(SFT_QUERIES) as COUNT_SUM | eval TIMEOUT_PERCENT=round(SFT_QUERIES*100/COUNT_SUM, 1) | eval DNPERCENT=NAME + \"(\"+TIMEOUT_PERCENT + \"%)\" | rename DNPERCENT as \"Domain Name\", SFT_QUERIES as \"Queries\" | fields \"Domain Name\", \"Queries\""
        cmd = config.search_py + " \"" + search_str + "\" --output_mode=json"
        os.system(cmd)
        try:
            retrived_data=open(config.json_file).read()
        except Exception, e:
            logger.error('search operation failed due to %s',e)
            raise Exception("Search operaiton failed, Please check Grid Configuraion")
        output_data = json.loads(retrived_data)
        results_list = output_data['results']
        logger.info("Appending % value in Domain name")
        M=self.test1
        L=results_list
        tot=0
        for H in L:
            tot+= int(H["Queries"])
        temp_test1=[]
        for N in M:
            comp_dict={}
            per="{0:.1f}".format((float(N["Queries"])/tot)*100)
            comp_dict["Domain Name"]=N["Domain Name"]+". ("+per+"%)"
            comp_dict["Queries"]=N["Queries"]
            temp_test1.append(comp_dict)
        search_dump(sys._getframe().f_code.co_name+"_search_output.txt",temp_test1,results_list)
        logger.info("dumping search results in '%s' 'dumps' directory",sys._getframe().f_code.co_name+"_search_output.txt")
        logger.info("compare_resutls with 'delta' value as 0")
        result = compare_results(temp_test1,results_list)
        if result == 0:
            logger.info("Search validation result: %s (PASS)",result)
        else:
            logger.error("Search validation result: %s (FAIL)",result)
        msg = 'Validation is not matching for object which is retrieved from DB %s', result
        assert result == 0, msg
    @classmethod
    def teardown_class(cls):
        logger.info('-'*15+"END:DNS Top Timed Out Recursive Queries."+'-'*15)
