"""
 Copyright (c) Infoblox Inc., 2016
 ReportName          : DNS Top Clients per Domain 
 ReportCategory      : DNS Query 
 Number of Test cases: 1
 Execution time      : 302.61 seconds
 Execution Group     : Hour Group (HG)
 Description         : DNS Top Clients per Domain reports will be udpated every hour and user has to configure Domain in 'Grid/Member Reporting Properteis'.

 Author : Raghavendra MN
 History: 05/24/2016 (Created)
"""
import config
import json
import os
import pytest
import pexpect
import re
import sys
import subprocess
import unittest
from time import sleep

import ib_utils.ib_NIOS as ib_NIOS
import ib_utils.ib_get as ib_get
from logger import logger 
from ib_utils.ib_system import search_dump as search_dump
from ib_utils.ib_validaiton import compare_results as compare_results

"""
TEST Steps:
      1.  Input/Preparation  : Prparation will be called by separte script as reports will be updated every one hour 
        a.Adding zones say, top_clients_per_domain.com with RR's domain1.top_clients_per_domain.com, domain2.top_clients_per_domain.com & domain3.top_clients_per_domain.com
        b.Next performing Query from differnt Clients
          Client#1
		domain1.top_clients_per_domain.com  (100)
		domain2.top_clients_per_domain.com  (90)
		domain3.top_clients_per_domain.com  (80)
	  Client#2
		domain1.top_clients_per_domain.com  (70)
		domain2.top_clients_per_domain.com  (60)
		domain3.top_clients_per_domain.com  (50)
	  Client#3
		domain1.top_clients_per_domain.com  (40)
		domain2.top_clients_per_domain.com  (30)
		domain3.top_clients_per_domain.com  (20)

      2.  Search     : Performing Search operaion with default/custom filter
      3.  Validation : comparing Search results with Reterived 'DNS Top Clients per Domain' report without delta.
"""

class DNSTopClientsperDomain(unittest.TestCase):
    @classmethod
    #Preparation
    def setup_class(cls):
        logger.info('-'*15+"START:DNS Top Clients per Domain"+'-'*15)
        logger.info ("Preparation has executed 1 hour before as this report will take 1 hour to update")
        cls.test1=[ \
	{"Domain":"domain1.top_clients_per_domain.com","Client":config.client_eth1_ip6,"Queries":"100"}, \
	{"Domain":"domain2.top_clients_per_domain.com","Client":config.client_eth1_ip6,"Queries":"90" }, \
        {"Domain":"domain3.top_clients_per_domain.com","Client":config.client_eth1_ip6,"Queries":"80"   }, \
        {"Domain":"domain1.top_clients_per_domain.com","Client":config.client_eth1_ip7,"Queries":"70"}, \
        {"Domain":"domain2.top_clients_per_domain.com","Client":config.client_eth1_ip7,"Queries":"60" }, \
        {"Domain":"domain3.top_clients_per_domain.com","Client":config.client_eth1_ip7,"Queries":"50" }, \
        {"Domain":"domain1.top_clients_per_domain.com","Client":config.client_eth1_ip8,"Queries":"40"}, \
        {"Domain":"domain2.top_clients_per_domain.com","Client":config.client_eth1_ip8,"Queries":"30" }, \
        {"Domain":"domain3.top_clients_per_domain.com","Client":config.client_eth1_ip8,"Queries":"20" }
        ]

        logger.info ("Input Json for validation")
        logger.info(json.dumps(cls.test1, sort_keys=True, indent=4, separators=(',', ': ')))

    def test_1_Default_Filter_validate_DNS_Top_Clients_per_Domain(self):
        logger.info("TestCase:test_1_Default_Filter_validate_DNS_Top_Clients_per_Domain")
        search_str=r"search index=ib_dns_summary report=si_top_clients_per_domain | stats sum(COUNT) as CLIENT_QUERIES by FQDN CLIENT | sort -CLIENT_QUERIES | head 10 | eventstats sum(CLIENT_QUERIES) as TOTAL | eval PERCENT=round(CLIENT_QUERIES*100/TOTAL,1) | eval PCLIENT=CLIENT+\"(\"+PERCENT+\"%)\" | rename FQDN as \"Domain\", CLIENT as \"Client\", CLIENT_QUERIES as Queries | fields \"Domain\", \"Client\", Queries"
        '''
        search_str=r"search index=ib_dns_summary report=si_top_clients_per_domain | lookup dns_viewkey_displayname_lookup VIEW output display_name | stats sum(COUNT) as CLIENT_QUERIES by FQDN CLIENT | sort -CLIENT_QUERIES | head 10 | eventstats sum(CLIENT_QUERIES) as TOTAL | eval PERCENT=round(CLIENT_QUERIES*100/TOTAL,1) | eval PCLIENT=CLIENT+\"(\"+PERCENT+\"%)\" | rename FQDN as \"Domain\", CLIENT as \"Client\", CLIENT_QUERIES as Queries | fields \"Domain\", \"Client\", Queries"
        '''
        cmd = config.search_py + " \"" + search_str + "\" --output_mode=json"
        logger.info (cmd)
        os.system(cmd)
        try:
            retrived_data=open(config.json_file).read()
        except Exception, e:
            logger.error('search operation failed due to %s',e)
            raise Exception("Looks like reporting service not started please check the GRID")
        output_data = json.loads(retrived_data)
        results_list = output_data['results']
        search_dump(sys._getframe().f_code.co_name+"_search_output.txt",self.test1,results_list)  
	logger.info("compare_resutls")
        result = compare_results(self.test1,results_list)
        if result == 0:
            logger.info("Search validation result: %s (PASS)",result)
        else:
            logger.error("Search validation result: %s (FAIL)",result)
        msg = 'Validation is not matching for object which is retrieved from DB %s', result
        assert result == 0, msg

    #Clean up
    @classmethod
    def teardown_class(cls):
        #deleting zones
        logger.info("Cleanup: Removing zones which was added in preparation step.")
        del_zone = ib_NIOS.wapi_request('GET', object_type="zone_auth?fqdn~=top_clients_per_domain.com")
        ref = json.loads(del_zone)[0]['_ref']
        del_status = ib_NIOS.wapi_request('DELETE', object_type = ref)
        logger.info('-'*15+"END:DNS Top Clients per Domain"+'-'*15)
